{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13522597,"sourceType":"datasetVersion","datasetId":8586316}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install wfdb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:07:27.011144Z","iopub.execute_input":"2025-10-28T18:07:27.011625Z","iopub.status.idle":"2025-10-28T18:07:30.360153Z","shell.execute_reply.started":"2025-10-28T18:07:27.011590Z","shell.execute_reply":"2025-10-28T18:07:30.359282Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import os, ast, random, time, math\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport wfdb\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import f1_score, classification_report\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:07:32.990046Z","iopub.execute_input":"2025-10-28T18:07:32.990873Z","iopub.status.idle":"2025-10-28T18:07:32.995948Z","shell.execute_reply.started":"2025-10-28T18:07:32.990843Z","shell.execute_reply":"2025-10-28T18:07:32.995170Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def set_seed(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = True\n\nset_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:07:37.298647Z","iopub.execute_input":"2025-10-28T18:07:37.299158Z","iopub.status.idle":"2025-10-28T18:07:37.308600Z","shell.execute_reply.started":"2025-10-28T18:07:37.299136Z","shell.execute_reply":"2025-10-28T18:07:37.307852Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# Keep the same file paths you already use in the notebook/files area\nDATA_ROOT = \"/kaggle/input/ptbxl-dataset\"\nCSV_DB   = f\"{DATA_ROOT}/ptbxl_database.csv\"\nCSV_SCP  = f\"{DATA_ROOT}/scp_statements.csv\"\nRECORDS  = f\"{DATA_ROOT}/records100\"  # contains 00000, 01000, ..., 21000\n\nassert Path(CSV_DB).exists(), \"ptbxl_database.csv not found at expected path\"\nassert Path(CSV_SCP).exists(), \"scp_statements.csv not found at expected path\"\nassert Path(RECORDS).exists(),  \"records100/ folder not found at expected path\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:08:02.678040Z","iopub.execute_input":"2025-10-28T18:08:02.678762Z","iopub.status.idle":"2025-10-28T18:08:02.739099Z","shell.execute_reply.started":"2025-10-28T18:08:02.678730Z","shell.execute_reply":"2025-10-28T18:08:02.738357Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"df = pd.read_csv(CSV_DB)\nscp = pd.read_csv(CSV_SCP)\n\n# Map SCP codes to diagnostic superclasses per PTBâ€‘XL documentation\nscp_diag = scp[scp['diagnostic'] == 1][['Unnamed: 0', 'diagnostic_class']]\nscp_diag.columns = ['scp_code','superclass']\nsuperclasses = ['NORM','MI','STTC','CD','HYP']  # fixed 5-class superclass setup\n\nscp_map = dict(zip(scp_diag['scp_code'].values, scp_diag['superclass'].values))\n\ndef extract_targets(s):\n    codes = ast.literal_eval(s)\n    labs = set()\n    for code in codes.keys():\n        if code in scp_map:\n            labs.add(scp_map[code])\n    y = np.zeros(len(superclasses), dtype=np.float32)\n    for i,c in enumerate(superclasses):\n        if c in labs:\n            y[i] = 1.0\n    return y\n\ndf['y'] = df['scp_codes'].apply(extract_targets)\ndf = df[df['y'].apply(lambda a: a.sum() > 0)].reset_index(drop=True)\nprint(\"Total labeled records:\", len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:08:12.770548Z","iopub.execute_input":"2025-10-28T18:08:12.770856Z","iopub.status.idle":"2025-10-28T18:08:33.464059Z","shell.execute_reply.started":"2025-10-28T18:08:12.770835Z","shell.execute_reply":"2025-10-28T18:08:33.463380Z"}},"outputs":[{"name":"stdout","text":"Total labeled records: 21388\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"train_df = df[df.strat_fold.isin(range(1,9))].copy()\nval_df   = df[df.strat_fold == 9].copy()\ntest_df  = df[df.strat_fold == 10].copy()\n\nprint(\"Train/Val/Test:\", len(train_df), len(val_df), len(test_df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:09:26.368184Z","iopub.execute_input":"2025-10-28T18:09:26.368462Z","iopub.status.idle":"2025-10-28T18:09:26.389696Z","shell.execute_reply.started":"2025-10-28T18:09:26.368442Z","shell.execute_reply":"2025-10-28T18:09:26.388930Z"}},"outputs":[{"name":"stdout","text":"Train/Val/Test: 17084 2146 2158\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"SIG_LEN = 1000  # 10 s at 100 Hz\nN_LEADS = 12\n\ndef resolve_lr_path(filename_lr: str) -> Path:\n    # filename_lr looks like 'records100/00000/00001_lr'\n    rel = filename_lr.lstrip(\"./\")\n    return (Path(DATA_ROOT) / rel).resolve()\n\ndef read_record_lr(row):\n    base = resolve_lr_path(row['filename_lr'])\n    # wfdb.rdsamp expects base path (no extension); it reads .hea/.dat automatically\n    sig, _ = wfdb.rdsamp(str(base))\n    sig = sig.astype(np.float32)\n\n    # pad/crop to SIG_LEN\n    if sig.shape[0] < SIG_LEN:\n        pad = SIG_LEN - sig.shape[0]\n        sig = np.pad(sig, ((0,pad),(0,0)), mode='constant')\n    elif sig.shape[0] > SIG_LEN:\n        sig = sig[:SIG_LEN]\n\n    # standardize per-lead, then transpose to (12, T)\n    m = sig.mean(axis=0, keepdims=True)\n    s = sig.std(axis=0, keepdims=True) + 1e-6\n    sig = (sig - m) / s\n    return sig.T  # (12, 1000)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:09:32.301481Z","iopub.execute_input":"2025-10-28T18:09:32.301794Z","iopub.status.idle":"2025-10-28T18:09:32.307968Z","shell.execute_reply.started":"2025-10-28T18:09:32.301772Z","shell.execute_reply":"2025-10-28T18:09:32.307182Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"class PTBXLDataset(Dataset):\n    def __init__(self, frame, single_lead=None):\n        self.frame = frame.reset_index(drop=True)\n        self.single_lead = single_lead  # index 0..11 or None for multi-lead\n        self.num_classes = len(superclasses)\n    def __len__(self): return len(self.frame)\n    def __getitem__(self, idx):\n        row = self.frame.iloc[idx]\n        x = read_record_lr(row)  # (12, T)\n        if self.single_lead is not None:\n            x = x[self.single_lead:self.single_lead+1, :]  # (1, T)\n        y = row['y'].astype(np.float32)\n        return torch.from_numpy(x), torch.from_numpy(y)\n\n# Example: use lead II (index 1) as single-lead; adjust if your prior lead differs\nSINGLE_LEAD_INDEX = 1\n\ntrain_single = PTBXLDataset(train_df, single_lead=SINGLE_LEAD_INDEX)\nval_single   = PTBXLDataset(val_df,   single_lead=SINGLE_LEAD_INDEX)\ntest_single  = PTBXLDataset(test_df,  single_lead=SINGLE_LEAD_INDEX)\n\ntrain_multi = PTBXLDataset(train_df, single_lead=None)\nval_multi   = PTBXLDataset(val_df,   single_lead=None)\ntest_multi  = PTBXLDataset(test_df,  single_lead=None)\n\nBATCH_TRAIN = 64\nBATCH_EVAL  = 128\n\ntrainloader_single = DataLoader(train_single, batch_size=BATCH_TRAIN, shuffle=True,\n                                num_workers=2, pin_memory=True, drop_last=True)\nvalloader_single   = DataLoader(val_single, batch_size=BATCH_EVAL, shuffle=False,\n                                num_workers=2, pin_memory=True)\ntestloader_single  = DataLoader(test_single, batch_size=BATCH_EVAL, shuffle=False,\n                                num_workers=2, pin_memory=True)\n\ntrainloader = DataLoader(train_multi, batch_size=BATCH_TRAIN, shuffle=True,\n                         num_workers=2, pin_memory=True, drop_last=True)\nvalloader   = DataLoader(val_multi, batch_size=BATCH_EVAL, shuffle=False,\n                         num_workers=2, pin_memory=True)\ntestloader  = DataLoader(test_multi, batch_size=BATCH_EVAL, shuffle=False,\n                         num_workers=2, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:09:38.412918Z","iopub.execute_input":"2025-10-28T18:09:38.413661Z","iopub.status.idle":"2025-10-28T18:09:38.429923Z","shell.execute_reply.started":"2025-10-28T18:09:38.413636Z","shell.execute_reply":"2025-10-28T18:09:38.429277Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, c_in, c_out, k=7, s=1, p=3):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv1d(c_in, c_out, k, s, p, bias=False),\n            nn.BatchNorm1d(c_out),\n            nn.ReLU(inplace=True),\n            nn.Conv1d(c_out, c_out, 3, 1, 1, bias=False),\n            nn.BatchNorm1d(c_out),\n            nn.ReLU(inplace=True),\n            nn.MaxPool1d(2)\n        )\n    def forward(self, x): return self.net(x)\n\nclass SingleLeadCNN(nn.Module):\n    def __init__(self, n_cls=5, feat_dim=128):\n        super().__init__()\n        self.b1 = ConvBlock(1, 64)\n        self.b2 = ConvBlock(64, 128)\n        self.b3 = ConvBlock(128, 128)\n        self.head = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Flatten(),\n            nn.Linear(128, feat_dim),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(feat_dim, n_cls)\n        )\n    def forward(self, x):\n        x = self.b1(x); x = self.b2(x); x = self.b3(x)\n        return self.head(x)\n\nclass MultiLeadCNN(nn.Module):\n    def __init__(self, n_leads=12, n_cls=5, feat_dim=256):\n        super().__init__()\n        self.stem = nn.Sequential(\n            nn.Conv1d(n_leads, 64, 7, 1, 3, bias=False),\n            nn.BatchNorm1d(64),\n            nn.ReLU(inplace=True)\n        )\n        self.b1 = ConvBlock(64, 128)\n        self.b2 = ConvBlock(128, 256)\n        self.b3 = ConvBlock(256, 256)\n        self.head = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Flatten(),\n            nn.Linear(256, feat_dim),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(feat_dim, n_cls)\n        )\n    def forward(self, x):\n        x = self.stem(x)\n        x = self.b1(x); x = self.b2(x); x = self.b3(x)\n        return self.head(x)\n\nsinglemodel = SingleLeadCNN(n_cls=len(superclasses)).to(device)\nmultileadmodel = MultiLeadCNN(n_leads=N_LEADS, n_cls=len(superclasses)).to(device)\n\nprint(\"Single params (M):\", sum(p.numel() for p in singlemodel.parameters())/1e6)\nprint(\"Multi  params (M):\", sum(p.numel() for p in multileadmodel.parameters())/1e6)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:09:49.225282Z","iopub.execute_input":"2025-10-28T18:09:49.225602Z","iopub.status.idle":"2025-10-28T18:09:49.263575Z","shell.execute_reply.started":"2025-10-28T18:09:49.225582Z","shell.execute_reply":"2025-10-28T18:09:49.262826Z"}},"outputs":[{"name":"stdout","text":"Single params (M): 0.301509\nMulti  params (M): 1.262981\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"def train_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    tot = 0.0\n    for xb, yb in loader:\n        xb, yb = xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        logits = model(xb)\n        loss = criterion(logits, yb)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n        optimizer.step()\n        tot += loss.item()\n    return tot / len(loader)\n\n@torch.no_grad()\ndef eval_probs(model, loader, criterion, device):\n    model.eval()\n    tot = 0.0\n    probs_list, tgts_list = [], []\n    for xb, yb in loader:\n        xb, yb = xb.to(device), yb.to(device)\n        logits = model(xb)\n        loss = criterion(logits, yb)\n        probs = torch.sigmoid(logits).cpu().numpy()\n        probs_list.append(probs); tgts_list.append(yb.cpu().numpy())\n        tot += loss.item()\n    P = np.vstack(probs_list); Y = np.vstack(tgts_list)\n    f1_05 = f1_score(Y, (P>=0.5).astype(int), average=\"macro\", zero_division=0)\n    return tot/len(loader), P, Y, f1_05\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:09:57.155082Z","iopub.execute_input":"2025-10-28T18:09:57.155670Z","iopub.status.idle":"2025-10-28T18:09:57.163260Z","shell.execute_reply.started":"2025-10-28T18:09:57.155643Z","shell.execute_reply":"2025-10-28T18:09:57.162454Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def find_best_thresholds(val_probs, val_tgts, grid=None):\n    if grid is None:\n        grid = np.linspace(0.1, 0.9, 81)\n    C = val_probs.shape[1]\n    best = np.full(C, 0.5, dtype=np.float32)\n    for c in range(C):\n        p, y = val_probs[:, c], val_tgts[:, c]\n        qs = np.quantile(p, np.linspace(0.05, 0.95, 19))\n        candidates = np.unique(np.concatenate([grid, qs]))\n        fbest, tbest = -1.0, 0.5\n        for t in candidates:\n            pred = (p >= t).astype(int)\n            f = f1_score(y, pred, zero_division=0)\n            if f > fbest:\n                fbest, tbest = f, float(t)\n        best[c] = tbest\n    return best\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:10:05.407765Z","iopub.execute_input":"2025-10-28T18:10:05.408261Z","iopub.status.idle":"2025-10-28T18:10:05.414932Z","shell.execute_reply.started":"2025-10-28T18:10:05.408237Z","shell.execute_reply":"2025-10-28T18:10:05.413859Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"singlecriterion = nn.BCEWithLogitsLoss()\nsingleoptimizer = torch.optim.Adam(singlemodel.parameters(), lr=1e-3)\nsinglescheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    singleoptimizer, mode='max', factor=0.5, patience=3\n)\nprint(\"Running\")\nbest_single = -1.0\nwait, patience = 0, 7\nEPOCHS_SINGLE = 30  # adjust to your prior run length\n\nfor epoch in range(1, EPOCHS_SINGLE+1):\n    tr = train_epoch(singlemodel, trainloader_single, singlecriterion, singleoptimizer, device)\n    vl, Vp, Vy, vf05 = eval_probs(singlemodel, valloader_single, singlecriterion, device)\n    thr = find_best_thresholds(Vp, Vy)\n    vbest = f1_score(Vy, (Vp>=thr).astype(int), average=\"macro\", zero_division=0)\n    singlescheduler.step(vbest)\n    print(f\"[Single] Epoch {epoch:02d} | train {tr:.4f} | val {vl:.4f} | F1@0.5 {vf05:.4f} | F1@best {vbest:.4f}\")\n    if vbest > best_single:\n        best_single, wait = vbest, 0\n        torch.save({\"model\": singlemodel.state_dict(), \"thr\": thr}, \"best_single.pt\")\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Single-lead early stop.\")\n            break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:11:30.719226Z","iopub.execute_input":"2025-10-28T18:11:30.719958Z","iopub.status.idle":"2025-10-28T18:26:21.000314Z","shell.execute_reply.started":"2025-10-28T18:11:30.719927Z","shell.execute_reply":"2025-10-28T18:26:20.999137Z"}},"outputs":[{"name":"stdout","text":"Running\n[Single] Epoch 01 | train 0.3847 | val 0.4158 | F1@0.5 0.4497 | F1@best 0.6159\n[Single] Epoch 02 | train 0.3721 | val 0.3860 | F1@0.5 0.5193 | F1@best 0.6163\n[Single] Epoch 03 | train 0.3634 | val 0.3756 | F1@0.5 0.4992 | F1@best 0.6252\n[Single] Epoch 04 | train 0.3595 | val 0.3779 | F1@0.5 0.5440 | F1@best 0.6250\n[Single] Epoch 05 | train 0.3563 | val 0.3699 | F1@0.5 0.5216 | F1@best 0.6334\n[Single] Epoch 06 | train 0.3526 | val 0.3787 | F1@0.5 0.5799 | F1@best 0.6315\n[Single] Epoch 07 | train 0.3509 | val 0.3793 | F1@0.5 0.5789 | F1@best 0.6338\n[Single] Epoch 08 | train 0.3477 | val 0.3629 | F1@0.5 0.5738 | F1@best 0.6451\n[Single] Epoch 09 | train 0.3461 | val 0.3669 | F1@0.5 0.5549 | F1@best 0.6459\n[Single] Epoch 10 | train 0.3418 | val 0.3773 | F1@0.5 0.5642 | F1@best 0.6394\n[Single] Epoch 11 | train 0.3415 | val 0.3710 | F1@0.5 0.5533 | F1@best 0.6431\n[Single] Epoch 12 | train 0.3388 | val 0.3591 | F1@0.5 0.5765 | F1@best 0.6445\n[Single] Epoch 13 | train 0.3377 | val 0.3671 | F1@0.5 0.5570 | F1@best 0.6433\n[Single] Epoch 14 | train 0.3273 | val 0.3633 | F1@0.5 0.5695 | F1@best 0.6443\n[Single] Epoch 15 | train 0.3253 | val 0.3673 | F1@0.5 0.5728 | F1@best 0.6435\n[Single] Epoch 16 | train 0.3228 | val 0.3625 | F1@0.5 0.5772 | F1@best 0.6427\nSingle-lead early stop.\n","output_type":"stream"}],"execution_count":44}]}